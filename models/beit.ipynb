{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model and tokenizer\n",
    "https://github.com/airsplay/lxmert/tree/master?tab=readme-ov-file#pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-20 18:14:10--  https://github.com/addf400/files/releases/download/beit3/beit3_base_patch16_480_vqa.pth\n",
      "Resolving github.com (github.com)... 20.200.245.247\n",
      "Connecting to github.com (github.com)|20.200.245.247|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/717694328/a382a6e7-7b1e-4d79-b9e6-702a6b1081f3?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-20T09%3A56%3A54Z&rscd=attachment%3B+filename%3Dbeit3_base_patch16_480_vqa.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-20T08%3A56%3A50Z&ske=2025-11-20T09%3A56%3A54Z&sks=b&skv=2018-11-09&sig=dTUpg43H9tyY6NYIfiONb4o9XiL3QvFWGj8RjaSbf3g%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MzYzMzY1MSwibmJmIjoxNzYzNjMwMDUxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.meXSrVxs7FLylIorSF6vkl7DRaAS0wUvHvgYVrXkNpQ&response-content-disposition=attachment%3B%20filename%3Dbeit3_base_patch16_480_vqa.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-11-20 18:14:11--  https://release-assets.githubusercontent.com/github-production-release-asset/717694328/a382a6e7-7b1e-4d79-b9e6-702a6b1081f3?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-20T09%3A56%3A54Z&rscd=attachment%3B+filename%3Dbeit3_base_patch16_480_vqa.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-20T08%3A56%3A50Z&ske=2025-11-20T09%3A56%3A54Z&sks=b&skv=2018-11-09&sig=dTUpg43H9tyY6NYIfiONb4o9XiL3QvFWGj8RjaSbf3g%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MzYzMzY1MSwibmJmIjoxNzYzNjMwMDUxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.meXSrVxs7FLylIorSF6vkl7DRaAS0wUvHvgYVrXkNpQ&response-content-disposition=attachment%3B%20filename%3Dbeit3_base_patch16_480_vqa.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456481107 (435M) [application/octet-stream]\n",
      "Saving to: ‘beit3_base_patch16_480_vqa.pth’\n",
      "\n",
      "beit3_base_patch16_ 100%[===================>] 435.33M  20.6MB/s    in 24s     \n",
      "\n",
      "2025-11-20 18:14:36 (17.8 MB/s) - ‘beit3_base_patch16_480_vqa.pth’ saved [456481107/456481107]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup environment \n",
    "!git clone https://github.com/microsoft/unilm.git\n",
    "!cd unilm/beit3\n",
    "!pip install -r requirements.txt   \n",
    "\n",
    "!wget https://github.com/addf400/files/releases/download/beit3/beit3_base_patch16_480_vqa.pth  \n",
    "!wget https://github.com/addf400/files/releases/download/beit3/beit3.spm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models import create_model \n",
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer(\"./beit3.spm\") \n",
    "model = \"beit_base_patch16_224\"\n",
    "task = \"vqav2\" \n",
    "drop_path = 0.1 \n",
    "vocab_size = 64010\n",
    "\n",
    "if task in (\"flickr30k\", \"coco_retrieval\"): \n",
    "    model_config = \"%s_retrieval\" % model\n",
    "elif task in (\"coco_captioning\", \"nocaps\"): \n",
    "    model_config = \"%s_captioning\" % model\n",
    "elif task in (\"imagenet\"): \n",
    "    model_config = \"%s_imageclassification\" % model\n",
    "else:\n",
    "    model_config = \"%s_%s\" % (model, task)\n",
    "\n",
    "model_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = create_model(\n",
    "    model_config,\n",
    "    pretrained=False,\n",
    "    drop_path_rate=drop_path,\n",
    "    vocab_size=vocab_size,\n",
    "    checkpoint_activations=None, \n",
    ")\n",
    "device = \"cuda:1\" \n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/work/yuna/HPA/data/vqav2_val_1k/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munilm/beit3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomDataset\n\u001b[0;32m----> 5\u001b[0m \u001b[43mCustomDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/work/yuna/HPA/data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/work/yuna/HPA/data/vqav2_val_1k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/yuna/HPA/models/unilm/beit3/datasets.py:625\u001b[0m, in \u001b[0;36mCustomDataset.make_dataset_index\u001b[0;34m(cls, data_path, tokenizer, json_data_path)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_dataset_index\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_path, tokenizer, json_data_path):\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    626\u001b[0m         dacon_train \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(json_data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/work/yuna/HPA/data/vqav2_val_1k/train.json'"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('unilm/beit3')\n",
    "from datasets import CustomDataset\n",
    "\n",
    "CustomDataset.make_dataset_index(\n",
    "    data_path=\"/home/work/yuna/HPA/data\",\n",
    "    tokenizer=tokenizer,\n",
    "    json_data_path=\"/home/work/yuna/HPA/data/vqav2_val_1k\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n이번 대회 데이터셋에 맞게, 아래 부분을 수정했습니다.(수정한 코드는 제 git에서 확인해주세요.)\\n    <수정 내용>\\n    dataset.py : CustomDataset Class 추가 및 task2dataset에 vqacustom 추가\\n    utils.py : import torch._six를 torch로 수정(module not found 에러 해결),\\n                pos_tokens = pos_tokens.float() 코드 추가(575번째 줄, 참고 : https://github.com/microsoft/unilm/issues/932),\\n                dump_prediction 함수(838번째 줄)에 있는 torch.distributed.barrier() 삭제(single GPU에서의 eval 위함, multi GPU의 경우 삭제 안해도 됨)\\n    engine_for_finetuning.py : def get_handler 함수에(442번째 줄) args.task == \"vqacustom\" 추가\\n    modeling_finetune.py : vqacustom 모델들 추가 및 num_classes부분 수정(label 수에 맞게)\\n    run_beit3_finetuning.py : parser.add_argument --task 부분에 vqacustom 추가, args.eval(357번째 줄)에 vqacustom 부분(367~370번째 줄) 추가\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "이번 대회 데이터셋에 맞게, 아래 부분을 수정했습니다.(수정한 코드는 제 git에서 확인해주세요.)\n",
    "    <수정 내용>\n",
    "    dataset.py : CustomDataset Class 추가 및 task2dataset에 vqacustom 추가\n",
    "    utils.py : import torch._six를 torch로 수정(module not found 에러 해결),\n",
    "                pos_tokens = pos_tokens.float() 코드 추가(575번째 줄, 참고 : https://github.com/microsoft/unilm/issues/932),\n",
    "                dump_prediction 함수(838번째 줄)에 있는 torch.distributed.barrier() 삭제(single GPU에서의 eval 위함, multi GPU의 경우 삭제 안해도 됨)\n",
    "    engine_for_finetuning.py : def get_handler 함수에(442번째 줄) args.task == \"vqacustom\" 추가\n",
    "    modeling_finetune.py : vqacustom 모델들 추가 및 num_classes부분 수정(label 수에 맞게)\n",
    "    run_beit3_finetuning.py : parser.add_argument --task 부분에 vqacustom 추가, args.eval(357번째 줄)에 vqacustom 부분(367~370번째 줄) 추가\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n",
      "Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=128, captioning_mask_prob=0.6, checkpoint_activations=None, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=0, cutmix_minmax=None, data_path='/home/work/yuna/VLMEval/data/val2014', device='cuda', dist_eval=False, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0.1, drop_worst_after=12000, drop_worst_ratio=0.2, enable_deepspeed=False, epochs=20, eval=True, eval_batch_size=None, finetune='', initial_scale_power=16, input_size=224, label_smoothing=0.1, layer_decay=0.9, length_penalty=0.6, local_rank=-1, log_dir=None, lr=0.0005, min_lr=1e-06, mixup=0, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='beit3_base_patch16_384', model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=1000, num_beams=3, num_max_bpe_tokens=64, num_workers=0, opt='adamw', opt_betas=[0.9, 0.999], opt_eps=1e-08, output_dir='./outputs/', pin_mem=True, randaug=False, recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=5, seed=0, sentencepiece_model='./beit3.spm', smoothing=0.1, start_epoch=0, task='vqacustom', task_cache_path='./outputs/', task_head_lr_weight=0, train_interpolation='bicubic', update_freq=1, vocab_size=64010, warmup_epochs=5, warmup_lr=1e-06, warmup_steps=-1, weight_decay=0.05, world_size=1, zero_stage=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"./unilm/beit3/run_beit3_finetuning.py\", line 452, in <module>\n",
      "    main(opts, ds_init)\n",
      "  File \"./unilm/beit3/run_beit3_finetuning.py\", line 244, in main\n",
      "    data_loader_train, data_loader_val = create_downstream_dataset(args)\n",
      "  File \"/home/work/yuna/HPA/models/unilm/beit3/datasets.py\", line 985, in create_downstream_dataset\n",
      "    create_dataset_by_split(args, split=\"train\", is_train=True), \\\n",
      "  File \"/home/work/yuna/HPA/models/unilm/beit3/datasets.py\", line 961, in create_dataset_by_split\n",
      "    dataset = dataset_class(\n",
      "  File \"/home/work/yuna/HPA/models/unilm/beit3/datasets.py\", line 569, in __init__\n",
      "    super().__init__(data_path=data_path, **kwargs)\n",
      "  File \"/home/work/yuna/HPA/models/unilm/beit3/datasets.py\", line 40, in __init__\n",
      "    with open(index_file, mode=\"r\", encoding=\"utf-8\") as reader:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/work/yuna/VLMEval/data/val2014/vqa.train.jsonl'\n"
     ]
    }
   ],
   "source": [
    "!python ./unilm/beit3/run_beit3_finetuning.py \\\n",
    "    --model beit3_base_patch16_384 \\\n",
    "    --task vqacustom \\\n",
    "    --batch_size 128 \\\n",
    "    --sentencepiece_model ./beit3.spm \\\n",
    "    --data_path /home/work/yuna/VLMEval/data/val2014 \\\n",
    "    --output_dir ./outputs/ \\\n",
    "    --eval\n",
    "# --finetune /content/drive/MyDrive/Dacon_multimodal/finetuned_model_file/custom_model.pth \\\n",
    "# --input_size 224 \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
